{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7caec450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b33a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d1e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dis_pred = pd.read_csv(\"heart_cleaned_encoded_smote.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e393bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = heart_dis_pred.drop(\"HeartDisease_No\",axis=1)\n",
    "target = heart_dis_pred[\"HeartDisease_No\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d70102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374300, 25)\n",
      "(374300,)\n",
      "(93576, 25)\n",
      "(93576,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022d0e",
   "metadata": {},
   "source": [
    "# ANN with Scaling + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9834f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_train,Y_train],axis = 1)\n",
    "train = np.array(data)\n",
    "data = pd.concat([X_test,Y_test],axis = 1)\n",
    "test = np.array(data)\n",
    "dim = len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c239cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 1]\n",
      "Recall for two batches: 0.9490488912636922 \n",
      "\n",
      "[0 1 0 ... 1 0 0]\n",
      "Recall for two batches: 0.9501795332136446 \n",
      "\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = hnswlib.Index(space='l2', dim=dim)\n",
    "p.init_index(max_elements=len(train), ef_construction=10000, M=dim, random_seed = 100)\n",
    "p.set_ef(1000)\n",
    "p.add_items(train,train[:,25])\n",
    "\n",
    "# prediction for train and evaluate\n",
    "labels, distances = p.knn_query(train[:,:25], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == train[:,25]), \"\\n\")\n",
    "\n",
    "# prediction for test and evaluate\n",
    "labels, distances = p.knn_query(np.array(test)[:,:25], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == np.array(test)[:,25]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09dcb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(p, open('model_ann.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0220a28",
   "metadata": {},
   "source": [
    "# ANN with Scaling + SMOTE + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ed23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"heart_cleaned_encoded_trained_pca.csv\")\n",
    "train = np.array(train)\n",
    "test = pd.read_csv(\"heart_cleaned_encoded_tested_pca.csv\")\n",
    "test = np.array(test)\n",
    "dim = len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7892093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "Recall for two batches: 0.7267117783344305 \n",
      "\n",
      "[1 1 1 ... 1 1 1]\n",
      "Recall for two batches: 0.9143982864022264 \n",
      "\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = hnswlib.Index(space='l2', dim=dim)\n",
    "p.init_index(max_elements=len(train), ef_construction=10000, M=dim, random_seed = 100)\n",
    "p.set_ef(1000)\n",
    "p.add_items(train,train[:,21])\n",
    "\n",
    "# prediction for train and evaluate\n",
    "labels, distances = p.knn_query(train[:,:21], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == train[:,21]), \"\\n\")\n",
    "\n",
    "# prediction for test and evaluate\n",
    "labels, distances = p.knn_query(np.array(test)[:,:21], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == np.array(test)[:,21]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a0263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(p, open('model_ann_pca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e5871",
   "metadata": {},
   "source": [
    "# ANN with Scaling + SMOTE + ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f050e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dis_train_pred = pd.read_csv(\"heart_cleaned_encoded_trained_ica.csv\")\n",
    "train = np.array(heart_dis_train_pred)\n",
    "heart_dis_test_pred = pd.read_csv(\"heart_cleaned_encoded_tested_ica.csv\")\n",
    "test = np.array(heart_dis_test_pred)\n",
    "dim = len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0374bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "Recall for two batches: 0.7266433841445169 \n",
      "\n",
      "[1 1 1 ... 1 1 1]\n",
      "Recall for two batches: 0.9143982864022264 \n",
      "\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = hnswlib.Index(space='l2', dim=dim)\n",
    "p.init_index(max_elements=len(train), ef_construction=10000, M=dim, random_seed = 100)\n",
    "p.set_ef(1000)\n",
    "p.add_items(train,train[:,21])\n",
    "\n",
    "# prediction for train and evaluate\n",
    "labels, distances = p.knn_query(train[:,:21], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == train[:,21]), \"\\n\")\n",
    "\n",
    "# prediction for test and evaluate\n",
    "labels, distances = p.knn_query(np.array(test)[:,:21], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == np.array(test)[:,21]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7bad004",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(p, open('model_ann_ica.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c711a4",
   "metadata": {},
   "source": [
    "# ANN with Scaling + SMOTE + LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19ccaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dis_train_pred = pd.read_csv(\"heart_cleaned_encoded_trained_lda.csv\")\n",
    "train = np.array(heart_dis_train_pred)\n",
    "heart_dis_test_pred = pd.read_csv(\"heart_cleaned_encoded_tested_lda.csv\")\n",
    "test = np.array(heart_dis_test_pred)\n",
    "dim = len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53bc13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "Recall for two batches: 0.7267737605690396 \n",
      "\n",
      "[1 1 1 ... 1 1 0]\n",
      "Recall for two batches: 0.9143826513860441 \n",
      "\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = hnswlib.Index(space='l2', dim=dim)\n",
    "p.init_index(max_elements=len(train), ef_construction=10000, M=dim, random_seed = 100)\n",
    "p.set_ef(1000)\n",
    "p.add_items(train,train[:,2])\n",
    "\n",
    "# prediction for train and evaluate\n",
    "labels, distances = p.knn_query(train[:,:2], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == train[:,2]), \"\\n\")\n",
    "\n",
    "# prediction for test and evaluate\n",
    "labels, distances = p.knn_query(np.array(test)[:,:2], k=1)\n",
    "print(labels.reshape(-1))\n",
    "print(\"Recall for two batches:\", np.mean(labels.reshape(-1) == np.array(test)[:,2]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca4321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(p, open('model_ann_lda.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
